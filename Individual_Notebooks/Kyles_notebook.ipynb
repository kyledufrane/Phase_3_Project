{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase III Project Technical Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authors: Kyle Dufrane and Brad Horn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatiron LLC has recently been awarded a contract to maintain wells in Tanzania. They're looking for a system to help develop preventative maintenance schedules by predicting pump failures and replacement schedules to better serve their client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given the business problem we hope to identify the following features through our EDA:\n",
    "* Are wells failing by geographic location?\n",
    "* Does well type or source effect pump longevity? \n",
    "* Does well management or payment effect pump longevity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This dataset comes from the Government of Tanzania and contains over ~59,000 wells with the earliest recorded construction year being 1966. Below you will see our data cleaning process.\n",
    "\n",
    "#### This dataset comes in three files, test_set, training_set_labels, and training_set_values. We will exclude the test set until the final model has been completed then predict and submit our findings. \n",
    "\n",
    "#### To start we will look at the training_set_labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/Training_set_labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-36fa1a676c8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import training labels CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_training_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/Training_set_labels.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/Training_set_labels.csv'"
     ]
    }
   ],
   "source": [
    "# Import training labels CSV\n",
    "df_training_labels = pd.read_csv('data/Training_set_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_labels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_labels.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on our counts, we can see that we will have to counter the class imbalance. We will fix this issue later on in our model building process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_labels['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training_set_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training values CSV\n",
    "df_training_values = pd.read_csv('data/Training_set_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the above cells output we can see that we have 40 predictive features to chose from being: \n",
    "\n",
    "* amount_tsh : Total static head (amount water available to waterpoint)\n",
    "* date_recorded : The date the row was entered\n",
    "* funder : Who funded the well\n",
    "* gps_height : Altitude of the well\n",
    "* installer : Organization that installed the well\n",
    "* longitude : GPS coordinate\n",
    "* latitude : GPS coordinate\n",
    "* wpt_name : Name of the waterpoint if there is one\n",
    "* num_private :Private use or not\n",
    "* basin : Geographic water basin\n",
    "* subvillage : Geographic location\n",
    "* region : Geographic location\n",
    "* region_code : Geographic location (coded)\n",
    "* district_code : Geographic location (coded)\n",
    "* lga : Geographic location\n",
    "* ward : Geographic location\n",
    "* population : Population around the well\n",
    "* public_meeting : True/False\n",
    "* recorded_by : Group entering this row of data\n",
    "* scheme_management : Who operates the waterpoint\n",
    "* scheme_name : Who operates the waterpoint\n",
    "* permit : If the waterpoint is permitted\n",
    "* construction_year : Year the waterpoint was constructed\n",
    "* extraction_type : The kind of extraction the waterpoint uses\n",
    "* extraction_type_group : The kind of extraction the waterpoint uses\n",
    "* extraction_type_class : The kind of extraction the waterpoint uses\n",
    "* management : How the waterpoint is managed\n",
    "* management_group : How the waterpoint is managed\n",
    "* payment : What the water costs\n",
    "* payment_type : What the water costs\n",
    "* water_quality : The quality of the water\n",
    "* quality_group : The quality of the water\n",
    "* quantity : The quantity of water\n",
    "* quantity_group : The quantity of water\n",
    "* source : The source of the water\n",
    "* source_type : The source of the water\n",
    "* source_class : The source of the water\n",
    "* waterpoint_type : The kind of waterpoint\n",
    "* waterpoint_type_group : The kind of waterpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A quick review of the Non-Null column shows that we are missing values in this data set. Below we will dive deeper into which columns are the most effected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Out of the 40 features 7 of them are missing values. A few items stand out:\n",
    "\n",
    "* Funder and installer have close to equal amounts of missing values\n",
    "* subvillage has the least amount of missing values\n",
    "* scheme_name is missing almost half of the values - we will drop this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping column from dataframe\n",
    "df_training_values.drop('scheme_name', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to explore more to see how we should handle these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of columns with missing values\n",
    "missing_values = ['funder', 'installer', 'subvillage', 'public_meeting',\\\n",
    "                  'scheme_management', 'permit']\n",
    "\n",
    "# creating a dataframe with above missing_values\n",
    "df_training_values[missing_values].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values[missing_values].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can now see that all of these features are of the dtype object which narrows down our options to dealing with the missing values. What are these features composed of? \n",
    "\n",
    "#### To start, lets take a look at our previous mentioned insite of funders and installers having close to the same amount of missing values. \n",
    "\n",
    "##### Note: prior to running the below cells I misread the value counts and thought that both of these columns had the same amount of NA values. The below lines raised the red flag of 'why are the true values the same but the false values differ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values[df_training_values['funder'].isna()]['installer'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values[df_training_values['installer'].isna()]['funder'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the above counts it looks like our counts vary minimally but enough so where we cannot attack these two columns as the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values['funder'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values[df_training_values['funder'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values['installer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values[df_training_values['installer'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values['subvillage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values['subvillage'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values['public_meeting'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values[df_training_values['public_meeting'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values[df_training_values['public_meeting'].isna()]['recorded_by'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the above dataframe you can see that all the items have been recorded by GeoData Consultants Ltd. Lets take a look at the whole dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values[df_training_values['recorded_by'] == 'GeoData Consultants Ltd']['recorded_by'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seeing how all of the data has been recorded by the same vendor this will have no impact on our modeling. This is another column that we can drop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values.drop('recorded_by', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values['scheme_management'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_values['permit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each column we will create two variables for modeling. One with the mode value for each column and one with a newly created variable denoted 'other'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new dataframe\n",
    "df_training_val_mode = df_training_values.copy()\n",
    "df_training_val_other = df_training_values.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NAN values to 'Other'\n",
    "\n",
    "df_training_val_other['funder'] = df_training_val_other['funder']\\\n",
    "                            .replace(np.nan, 'Other', regex = True)\n",
    "\n",
    "df_training_val_other['installer'] = df_training_val_other['installer']\\\n",
    "                                .replace(np.nan, 'Other', regex = True)\n",
    "\n",
    "df_training_val_other['subvillage'] = df_training_val_other['subvillage']\\\n",
    "                                    .replace(np.nan, 'Other', regex = True)\n",
    "\n",
    "df_training_val_other['public_meeting'] = df_training_val_other['public_meeting']\\\n",
    "                                            .replace(np.nan, 'Other', regex = True)\n",
    "\n",
    "df_training_val_other['scheme_management'] = df_training_val_other['scheme_management']\\\n",
    "                                                .replace(np.nan, 'Other', regex = True)\n",
    "\n",
    "df_training_val_other['permit'] = df_training_val_other['permit']\\\n",
    "                            .replace(np.nan, 'Other', regex = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NAN values with most common feature based on count\n",
    "\n",
    "df_training_val_mode['funder'].fillna(df_training_val_mode['funder']\\\n",
    "                        .value_counts().index[0], inplace = True)\n",
    "\n",
    "df_training_val_mode['installer'].fillna(df_training_val_mode['installer']\\\n",
    "                                .value_counts().index[0], inplace = True)\n",
    "\n",
    "df_training_val_mode['subvillage'].fillna(df_training_val_mode['subvillage']\\\n",
    "                                    .value_counts().index[0], inplace = True)\n",
    "\n",
    "df_training_val_mode['public_meeting'].fillna(df_training_val_mode['public_meeting']\\\n",
    "                                            .value_counts().index[0], inplace = True)\n",
    "\n",
    "df_training_val_mode['scheme_management'].fillna(df_training_val_mode['scheme_management']\\\n",
    "                                                 .value_counts().index[0], inplace = True)\n",
    "\n",
    "df_training_val_mode['permit'].fillna(df_training_val_mode['permit']\\\n",
    "                            .value_counts().index[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_val_mode.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_val_other.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets merge the tables so we only have two data sets to work with. To start, both dataframes have an ID column so we will create a new column on our target set and drop the identical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_labels['id_2'] = df_training_labels['id']\n",
    "df_training_labels.drop('id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we will join our tables and create two dataframes for mode and other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mode = pd.concat([df_training_val_mode, df_training_labels], join = 'inner', axis = 1)\n",
    "df_other = pd.concat([df_training_val_other, df_training_labels], join = 'inner', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mode[df_mode['id'] == df_mode['id_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other[df_other['id'] == df_other['id_2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As seen above our total rows equal that of the normal dataframe so we can conclude that our merges have been successful and we can drop our id_2 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mode.drop(['id_2'], axis = 1, inplace = True)\n",
    "df_other.drop(['id_2'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Columns to Drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Id columns and date_recorded are considered admin columns and will not have much predictive power in our model therefore we can drop these columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mode.drop(['id', 'date_recorded'], axis = 1, inplace = True)\n",
    "df_other.drop(['id', 'date_recorded'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_totals(dataframe, filter_column, filter_groupby):\n",
    "\n",
    "        '''\n",
    "        **** filter_column & filter_groupby need to be passed\n",
    "        as strings ****\n",
    "\n",
    "        1. get_totals will calculate the sum of the variables\n",
    "        within a column and return a new column with the \n",
    "        sum of their total occurances in the dataframe\n",
    "        \n",
    "        2. get_totals will calulate the percentage of the \n",
    "        values column vs the total values\n",
    "\n",
    "        dataframe = pandas dataframe\n",
    "        filter_column = column to filter by\n",
    "        filter_groupby = groupby column to filter by\n",
    "\n",
    "        '''\n",
    "\n",
    "        df_new = pd.DataFrame(dataframe.groupby(filter_groupby)[filter_column].value_counts())\n",
    "        df_new[f'{filter_groupby}_values'] = df_new[filter_column]\n",
    "        df_new.drop(filter_column, axis = 1, inplace = True)\n",
    "        df_new.reset_index(inplace = True)\n",
    "\n",
    "        types = set()\n",
    "\n",
    "        for idx, value in enumerate(df_new[f'{filter_groupby}_values']):\n",
    "            for type_ in df_new[filter_column]:\n",
    "                types.add(type_)\n",
    "            \n",
    "        total_values = {}\n",
    "            \n",
    "        for value in types:\n",
    "            total_values[value] = df_new[df_new[filter_column] == value][f'{filter_groupby}_values'].sum()\n",
    "\n",
    "        df_new[f'{filter_groupby}_total_values'] = df_new[filter_column].map(total_values)\n",
    "\n",
    "        df_new[f'{filter_groupby}_percentage'] = df_new[f'{filter_groupby}_values'] / df_new[f'{filter_groupby}_total_values']\n",
    "            \n",
    "        return df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function_df = df.drop('status_group', axis = 1)\n",
    "\n",
    "# percentage_dict = {}\n",
    "\n",
    "# for idx, column in enumerate(function_df.columns):\n",
    "#     percentage_dict[column] = get_totals(df, column, 'status_group')\n",
    "\n",
    "# pickle_out = open('percentage_dict.pickle', 'wb')\n",
    "# pickle.dump(percentage_dict, pickle_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('percentage_dict.pickle', 'rb')\n",
    "\n",
    "percentage_dict = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mode.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = percentage_dict['source']\n",
    "functional = source[source['status_group'] == 'functional']\n",
    "functional\n",
    "\n",
    "plt.bar(source['source'], source['status_group_percentage'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Top Functional Wells by Source')\n",
    "plt.savefig('saved_objects/source_bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = percentage_dict['payment']\n",
    "functional = source[source['status_group'] == 'functional']\n",
    "functional\n",
    "\n",
    "plt.bar(source['payment'], source['status_group_percentage'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Money?')\n",
    "plt.savefig('saved_objects/money_bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To start our modeling process we will use only our integers and floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mode_fsm = df_mode.select_dtypes(['int64', 'float64'])\n",
    "y_mode_fsm = df_mode['status_group']\n",
    "\n",
    "X_other_fsm = df_other.select_dtypes(['int64','float64'])\n",
    "y_other_fsm = df_other['status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mode_train, X_mode_test, y_mode_train, y__mode_test = train_test_split(X_mode_fsm,y_mode_fsm, random_state = 42, stratify = y_mode_fsm)\n",
    "\n",
    "X_other_train, X_other_test, y_other_train, y_other_test = train_test_split(X_other_fsm,y_other_fsm, random_state = 42, stratify = y_mode_fsm)\n",
    "\n",
    "\n",
    "dtc_mode = DecisionTreeClassifier()\n",
    "dtc_other = DecisionTreeClassifier()\n",
    "\n",
    "dtc_mode.fit(X_mode_train, y_mode_train)\n",
    "dtc_other.fit(X_other_train, y_other_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dtc_mode.score(X_mode_train, y_mode_train))\n",
    "print(dtc_other.score(X_other_train, y_other_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_mode = dtc_mode.predict(X_mode_train)\n",
    "y_hat_other = dtc_other.predict(X_other_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mode recall:', recall_score(y_mode_train, y_hat_mode, average = 'macro'))\n",
    "print('mode precision:', precision_score(y_mode_train, y_hat_mode, average = 'macro'))\n",
    "print('mode f1 score:', f1_score(y_mode_train, y_hat_mode, average = 'macro'))\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "\n",
    "print('ohter recall:', recall_score(y_other_train, y_hat_other, average = 'macro'))\n",
    "print('other precision:', precision_score(y_other_train, y_hat_other, average = 'macro'))\n",
    "print('other f1 score:', f1_score(y_other_train, y_hat_other, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(dtc_mode, X_mode_train, y_mode_train, cv = 3, scoring = 'recall_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(dtc_other, X_mode_train, y_mode_train, cv = 3, scoring = 'recall_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cross val scores are pretty consitent across the folds. This doesnt give us much insight as far as our NAN replacements in during the EDA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have our baseline established we will loop through other models to see if we can get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_selection = [LogisticRegression(random_state = 42, max_iter = 1000, n_jobs = -1),\\\n",
    "#                    RandomForestClassifier(random_state = 42, n_jobs = -1),\\\n",
    "#                    DecisionTreeClassifier(), KNeighborsClassifier(n_jobs = -1), \n",
    "#                   SVC(random_state = 42)]\n",
    "\n",
    "# vanilla_models = {}\n",
    "\n",
    "# for idx_mode, model in enumerate(model_selection):\n",
    "#     vanilla_models[idx_mode] = model.fit(X_mode_train, y_mode_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, val in enumerate(vanilla_models.values()):\n",
    "#     print(val, val.score(X_mode_train, y_mode_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the scores above, our scores are the best using RandomForestClassifier and DecisionTreeClassifier. Let's did deeper into these two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select models from dictionary\n",
    "# rfc = vanilla_models[1]\n",
    "# dtc = vanilla_models[2]\n",
    "\n",
    "# # predict on each model\n",
    "\n",
    "# rfc_mode_yhat = rfc.predict(X_mode_train)\n",
    "# dtc_mode_yhat = dtc.predict(X_mode_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Review scores for both models\n",
    "\n",
    "# print('rfc recall:', recall_score(y_mode_train, rfc_mode_yhat, average = 'macro'))\n",
    "# print('rfc precision:', precision_score(y_mode_train, rfc_mode_yhat, average = 'macro'))\n",
    "# print('rfc f1 score:', f1_score(y_mode_train, rfc_mode_yhat, average = 'macro'))\n",
    "\n",
    "# print('---------------------------------------------------------')\n",
    "\n",
    "# print('dtc recall:', recall_score(y_mode_train, dtc_mode_yhat, average = 'macro'))\n",
    "# print('dtc precision:', precision_score(y_mode_train, dtc_mode_yhat, average = 'macro'))\n",
    "# print('dtc f1 score:', f1_score(y_mode_train, dtc_mode_yhat, average = 'macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small advantage do the decision tree classifier. Lets see if our cross val & auc score shows anymore insights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(rfc, X_mode_train, y_mode_train, cv = 5, n_jobs=-1, scoring = 'recall_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score(dtc, X_mode_train, y_mode_train, cv = 5, n_jobs = -1, scoring = 'recall_macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since our stakeholder is considered with pump failures we need to avoid False Negatives. I.E. we do not want to say the bump is broken when it in fact it is operational. Therefore we need to focus on our recall score and tune our model appropriately which is why we're using the recall_macro score. As seen above our Random Forest is performing the best. We will move forward with tuning this model going forward.\n",
    "\n",
    "### Our models above only utilized our numerical values. We will now begin using our categorical features and identify feature importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate data by target and predictors\n",
    "# X_cat = df_mode.drop('status_group', axis = 1)\n",
    "# y_cat = df_mode['status_group']\n",
    "\n",
    "# # Perform train test split\n",
    "# X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(X_cat, y_cat, random_state = 42, stratify = y_cat)\n",
    "\n",
    "# # One hot encoded categorical data\n",
    "# ohe = OneHotEncoder(drop = 'first')\n",
    "\n",
    "\n",
    "# # Select initial parameters\n",
    "# df_feat_import = X_train_cat[['extraction_type', 'management', 'payment', 'water_quality', 'source', 'source_class', 'region_code', 'district_code']]\n",
    "\n",
    "# # fit transform data\n",
    "# X_mode_train_enc = ohe.fit_transform(df_feat_import)\n",
    "\n",
    "# # Instantiate model\n",
    "# rfc_feat_import = RandomForestClassifier(random_state = 42, class_weight= 'balanced', n_jobs = -1)\n",
    "\n",
    "\n",
    "# # Fit encoded data to model\n",
    "# rfc_feat_import.fit(X_mode_train_enc, y_train_cat)\n",
    "\n",
    "# # Model score\n",
    "# rfc_feat_import.score(X_mode_train_enc, y_train_cat)\n",
    "\n",
    "# # Predict on training data\n",
    "# rfc_yhat_1 = rfc_feat_import.predict(X_mode_train_enc)\n",
    "\n",
    "# # Recall score on training data\n",
    "# recall_score(y_train_cat, rfc_yhat, average='macro')\n",
    "\n",
    "# # Precision score on training data\n",
    "# precision_score(y_train_cat, rfc_yhat, average='macro')\n",
    "\n",
    "# #F1 Score on training data\n",
    "# f1_score(y_train_cat, rfc_yhat, average='macro')\n",
    "\n",
    "# # 5-fold cross validation\n",
    "# cross_val_score(rfc_feat_import, X_mode_train_enc, y_train_cat, cv = 5, scoring = 'recall_macro')\n",
    "\n",
    "# plot_confusion_matrix(rfc_feat_import, X_mode_train_enc, y_train_cat);\n",
    "\n",
    "# visualizer = ROCAUC(clf)\n",
    "# visualizer.fit(X_train, y_train)\n",
    "# visualizer.score(X_train, y_train)\n",
    "# visualizer.show()\n",
    "\n",
    "# #### Adding features to see if our model improves all other steps are a repeat from above\n",
    "\n",
    "# ohe = OneHotEncoder(drop = 'first')\n",
    "\n",
    "# df_feat_import = X_train_cat[[\n",
    "#  'source_type',\n",
    "#  'region',\n",
    "#  'district_code',\n",
    "#  'public_meeting',\n",
    "#  'extraction_type',\n",
    "#  'extraction_type_group',\n",
    "#  'extraction_type_class',\n",
    "#  'management',\n",
    "#  'payment_type',\n",
    "#  'quantity_group',\n",
    "#  'source',\n",
    "#  'source_class',\n",
    "#  'waterpoint_type_group']]\n",
    "\n",
    "# X_mode_train_enc = ohe.fit_transform(df_feat_import)\n",
    "\n",
    "# rfc_feat_import = RandomForestClassifier(random_state = 42, class_weight= 'balanced', n_jobs = -1)\n",
    "\n",
    "# rfc_feat_import.fit(X_mode_train_enc, y_train_cat)\n",
    "\n",
    "# rfc_feat_import.score(X_mode_train_enc, y_train_cat)\n",
    "\n",
    "# rfc_yhat = rfc_feat_import.predict(X_mode_train_enc)\n",
    "\n",
    "# recall_score(y_train_cat, rfc_yhat, average = 'macro')\n",
    "\n",
    "# cross_val_score(rfc_feat_import, X_mode_train_enc, y_train_cat, cv = 5, scoring = 'recall_macro')\n",
    "\n",
    "# plot_confusion_matrix(rfc_feat_import, X_mode_train_enc, y_train_cat);\n",
    "\n",
    "# visualizer = ROCAUC(clf)\n",
    "# visualizer.fit(X_train, y_train)\n",
    "# visualizer.score(X_train, y_train)\n",
    "# visualizer.show()\n",
    "\n",
    "# #### Adding features to see if our model improves all other steps are a repeat from above\n",
    "\n",
    "# ohe = OneHotEncoder(drop = 'first')\n",
    "\n",
    "# df_feat_import = X_train_cat[['region_code', 'source_type', 'basin', 'region', 'region_code', 'district_code',\\\n",
    "#                    'public_meeting', 'scheme_management', 'permit', 'construction_year', 'extraction_type',\\\n",
    "#                   'extraction_type_group', 'extraction_type_class','management',\\\n",
    "#                    'management_group', 'payment', 'payment_type', 'water_quality',\\\n",
    "#                   'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
    "#                    'source_class', 'waterpoint_type', 'waterpoint_type_group']]\n",
    "\n",
    "# X_mode_train_enc = ohe.fit_transform(df_feat_import)\n",
    "\n",
    "# rfc_feat_import = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# rfc_feat_import.fit(X_mode_train_enc, y_train_cat)\n",
    "\n",
    "# rfc_feat_import.score(X_mode_train_enc, y_train_cat)\n",
    "\n",
    "# rfc_yhat = rfc_feat_import.predict(X_mode_train_enc)\n",
    "\n",
    "# recall_score(y_train_cat, rfc_yhat, average = 'macro')\n",
    "\n",
    "# cross_val_score(rfc_feat_import, X_mode_train_enc, y_train_cat, cv = 5, scoring = 'recall_macro')\n",
    "\n",
    "# plot_confusion_matrix(rfc_feat_import, X_mode_train_enc, y_train_cat);\n",
    "\n",
    "# visualizer = ROCAUC(clf)\n",
    "# visualizer.fit(X_train, y_train)\n",
    "# visualizer.score(X_train, y_train)\n",
    "# visualizer.show()\n",
    "\n",
    "# ### Now that we have seen model improvement we will use a GridSearch to find our best parameters\n",
    "\n",
    "# # param_grid = {\n",
    "# #  'max_depth': [3,10, None],\n",
    "# #  'criterion': ['gini', 'entropy'],\n",
    "# #  'min_samples_leaf': [1, 2, 4],\n",
    "# #  'n_estimators': [100, 500],\n",
    "# #  'class_weight': ['balanced', 'balanced_subsample'],\n",
    "# #  'n_jobs': [-1]\n",
    "# # }\n",
    "\n",
    "# # grid_search = GridSearchCV(rfc_feat_import, param_grid, n_jobs=-1, cv = 3, return_train_score=True)\n",
    "\n",
    "# # grid_search.fit(X_mode_train_enc, y_train_cat)\n",
    "\n",
    "# # 'grid_search.best_params_'\n",
    "\n",
    "# # \"'class_weight': 'balanced',\n",
    "# #  'criterion': 'entropy',\n",
    "# #  'max_depth': None,\n",
    "# #  'min_samples_leaf': 1,\n",
    "# #  'n_estimators': 500,\n",
    "# #  'n_jobs': -1\")\n",
    "\n",
    "# #### Base on our best_params_ we will input these features into a new to model and repeat the above steps\n",
    "\n",
    "# ohe = OneHotEncoder(drop = 'first')\n",
    "\n",
    "# df_feat_import = X_train_cat[['region_code', 'source_type', 'basin', 'region', 'region_code', 'district_code',\\\n",
    "#                    'public_meeting', 'scheme_management', 'permit', 'construction_year', 'extraction_type',\\\n",
    "#                   'extraction_type_group', 'extraction_type_class','management',\\\n",
    "#                    'management_group', 'payment', 'payment_type', 'water_quality',\\\n",
    "#                   'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
    "#                    'source_class', 'waterpoint_type', 'waterpoint_type_group']]\n",
    "\n",
    "# X_mode_train_enc = ohe.fit_transform(df_feat_import)\n",
    "\n",
    "# rfc_feat_import = RandomForestClassifier(random_state = 42, class_weight='balanced', criterion='entropy', n_estimators = 500, n_jobs=-1)\n",
    "\n",
    "# rfc_feat_import.fit(X_mode_train_enc, y_train_cat)\n",
    "\n",
    "# rfc_feat_import.score(X_mode_train_enc, y_train_cat)\n",
    "\n",
    "# rfc_yhat = rfc_feat_import.predict(X_mode_train_enc)\n",
    "\n",
    "# recall_score(y_train_cat, rfc_yhat, average = 'macro')\n",
    "\n",
    "# cross_val_score(rfc_feat_import, X_mode_train_enc, y_train_cat, cv = 5, scoring = 'recall_macro')\n",
    "\n",
    "# plot_confusion_matrix(rfc_feat_import, X_mode_train_enc, y_train_cat);\n",
    "\n",
    "# visualizer = ROCAUC(clf)\n",
    "# visualizer.fit(X_train, y_train)\n",
    "# visualizer.score(X_train, y_train)\n",
    "# visualizer.show()\n",
    "\n",
    "# ### Based on our previous model our recall jumped to 85.86% from 77.56%! Also, our cross_val_score is within < 2% span which is showing that our model has low bias. \n",
    "\n",
    "# ### Previously we separated our data into two data frames. We will repeat the above process with the second dataframe to see if we get different results.\n",
    "\n",
    "# X_other = df_other.drop('status_group', axis = 1)\n",
    "# y_other = df_other['status_group']\n",
    "\n",
    "# X_train_other, X_test_other, y_train_other, y_test_other = train_test_split(X_other, y_other, random_state = 42, stratify = y_other)\n",
    "\n",
    "# ohe = OneHotEncoder(drop = 'first')\n",
    "\n",
    "# df_feat_import = X_train_other[['extraction_type', 'management', 'payment', 'water_quality', 'source', 'source_class', 'region_code', 'district_code']]\n",
    "\n",
    "# X_other_train_enc = ohe.fit_transform(df_feat_import)\n",
    "\n",
    "# rfc_feat_import = RandomForestClassifier(random_state = 42, class_weight= 'balanced', n_jobs = -1)\n",
    "\n",
    "# rfc_feat_import.fit(X_other_train_enc, y_train_other)\n",
    "\n",
    "# rfc_feat_import.score(X_other_train_enc, y_train_other)\n",
    "\n",
    "# rfc_yhat = rfc_feat_import.predict(X_other_train_enc)\n",
    "\n",
    "# recall_score(y_train_other, rfc_yhat, average='macro')\n",
    "\n",
    "# cross_val_score(rfc_feat_import, X_other_train_enc, y_train_other, cv = 5, scoring = 'recall_macro')\n",
    "\n",
    "# plot_confusion_matrix(rfc_feat_import, X_other_train_enc, y_train_other);\n",
    "\n",
    "# visualizer = ROCAUC(clf)\n",
    "# visualizer.fit(X_train, y_train)\n",
    "# visualizer.score(X_train, y_train)\n",
    "# visualizer.show()\n",
    "\n",
    "# ohe = OneHotEncoder(drop = 'first')\n",
    "\n",
    "# df_feat_import = X_train_other[[\n",
    "#  'source_type',\n",
    "#  'region',\n",
    "#  'district_code',\n",
    "#  'extraction_type',\n",
    "#  'extraction_type_group',\n",
    "#  'extraction_type_class',\n",
    "#  'management',\n",
    "#  'payment_type',\n",
    "#  'quantity_group',\n",
    "#  'source',\n",
    "#  'source_class',\n",
    "#  'waterpoint_type_group']]\n",
    "\n",
    "# X_other_train_enc = ohe.fit_transform(df_feat_import)\n",
    "\n",
    "# rfc_feat_import = RandomForestClassifier(random_state = 42, class_weight= 'balanced', n_jobs = -1)\n",
    "\n",
    "# rfc_feat_import.fit(X_other_train_enc, y_train_other)\n",
    "\n",
    "# rfc_feat_import.score(X_other_train_enc, y_train_other)\n",
    "\n",
    "# rfc_yhat = rfc_feat_import.predict(X_other_train_enc)\n",
    "\n",
    "# recall_score(y_train_other, rfc_yhat, average='macro')\n",
    "\n",
    "# cross_val_score(rfc_feat_import, X_other_train_enc, y_train_other, cv = 5, scoring = 'recall_macro')\n",
    "\n",
    "# plot_confusion_matrix(rfc_feat_import, X_other_train_enc, y_train_other);\n",
    "\n",
    "# visualizer = ROCAUC(clf)\n",
    "# visualizer.fit(X_train, y_train)\n",
    "# visualizer.score(X_train, y_train)\n",
    "# visualizer.show()\n",
    "\n",
    "# ohe = OneHotEncoder(drop = 'first')\n",
    "\n",
    "# df_feat_import = X_train_other[['region_code', 'source_type', 'basin', 'region', 'region_code', 'district_code',\\\n",
    "#                     'scheme_management', 'construction_year', 'extraction_type',\\\n",
    "#                   'extraction_type_group', 'extraction_type_class','management',\\\n",
    "#                    'management_group', 'payment', 'payment_type', 'water_quality',\\\n",
    "#                   'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
    "#                    'source_class', 'waterpoint_type', 'waterpoint_type_group']]\n",
    "\n",
    "# X_other_train_enc = ohe.fit_transform(df_feat_import)\n",
    "\n",
    "# rfc_feat_import = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# rfc_feat_import.fit(X_other_train_enc, y_train_other)\n",
    "\n",
    "# rfc_feat_import.score(X_other_train_enc, y_train_other)\n",
    "\n",
    "# rfc_yhat = rfc_feat_import.predict(X_other_train_enc)\n",
    "\n",
    "# recall_score(y_train_other, rfc_yhat, average='macro')\n",
    "\n",
    "# cross_val_score(rfc_feat_import, X_other_train_enc, y_train_other, cv = 5, scoring = 'recall_macro')\n",
    "\n",
    "# plot_confusion_matrix(rfc_feat_import, X_other_train_enc, y_train_other);\n",
    "\n",
    "# visualizer = ROCAUC(clf)\n",
    "# visualizer.fit(X_train, y_train)\n",
    "# visualizer.score(X_train, y_train)\n",
    "# visualizer.show()\n",
    "\n",
    "# param_grid = {\n",
    "#  'max_depth': [3,10, None],\n",
    "#  'criterion': ['gini', 'entropy'],\n",
    "#  'min_samples_leaf': [1, 2, 4],\n",
    "#  'n_estimators': [100, 500],\n",
    "#  'class_weight': ['balanced', 'balanced_subsample'],\n",
    "#  'n_jobs': [-1]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(rfc_feat_import, param_grid, n_jobs=-1, cv = 3, return_train_score=True)\n",
    "\n",
    "# grid_search.fit(X_other_train_enc, y_train_other)\n",
    "\n",
    "# grid_search.best_params_\n",
    "\n",
    "# grid_search.best_score_\n",
    "\n",
    "# ohe = OneHotEncoder(drop = 'first')\n",
    "\n",
    "# df_feat_import = X_train_other[['region_code', 'source_type', 'basin', 'region', 'region_code', 'district_code',\\\n",
    "#                     'scheme_management', 'construction_year', 'extraction_type',\\\n",
    "#                   'extraction_type_group', 'extraction_type_class','management',\\\n",
    "#                    'management_group', 'payment', 'payment_type', 'water_quality',\\\n",
    "#                   'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
    "#                    'source_class', 'waterpoint_type', 'waterpoint_type_group']]\n",
    "\n",
    "# X_other_train_enc = ohe.fit_transform(df_feat_import)\n",
    "\n",
    "# rfc_feat_import = RandomForestClassifier(class_weight='balanced_subsample', criterion='gini', min_samples_leaf=1, n_estimators=100, random_state = 42, n_jobs=-1)\n",
    "\n",
    "# rfc_feat_import.fit(X_other_train_enc, y_train_other)\n",
    "\n",
    "# rfc_feat_import.score(X_other_train_enc, y_train_other)\n",
    "\n",
    "# rfc_yhat = rfc_feat_import.predict(X_other_train_enc)\n",
    "\n",
    "# recall_score(y_train_other, rfc_yhat, average='macro')\n",
    "\n",
    "# cross_val_score(rfc_feat_import, X_other_train_enc, y_train_other, cv = 5, scoring = 'recall_macro')\n",
    "\n",
    "# plot_confusion_matrix(rfc_feat_import, X_other_train_enc, y_train_other);\n",
    "\n",
    "# visualizer = ROCAUC(clf)\n",
    "# visualizer.fit(X_train, y_train)\n",
    "# visualizer.score(X_train, y_train)\n",
    "# visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This model performed almost as good as the first one. With the first model getting a recall score of 85.86% it has beaten the second model by .58%, not much but still an increase that we're looking for!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical & Numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally we will build a pipeline to incorporate all of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mode[['region_code', 'source_type', 'basin', 'region', 'district_code',\\\n",
    "                   'public_meeting', 'scheme_management', 'permit', 'extraction_type',\\\n",
    "                  'extraction_type_group', 'extraction_type_class','management',\\\n",
    "                   'management_group', 'payment', 'payment_type', 'water_quality',\\\n",
    "                  'quality_group', 'quantity', 'quantity_group', 'source',\n",
    "                   'source_class', 'waterpoint_type', 'waterpoint_type_group', 'gps_height', 'population',\\\n",
    "                   'construction_year', 'num_private', 'longitude', 'latitude']]\n",
    "\n",
    "y = df_mode['status_group']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['region_code', 'source_type', 'basin', 'region', 'district_code',\\\n",
    "                   'public_meeting', 'scheme_management', 'permit', 'construction_year', 'extraction_type',\\\n",
    "                  'extraction_type_group', 'extraction_type_class','management',\\\n",
    "                   'management_group', 'payment', 'payment_type', 'water_quality',\\\n",
    "                  'quality_group', 'quantity', 'quantity_group', 'source',\n",
    "                   'source_class', 'waterpoint_type', 'waterpoint_type_group']\n",
    "\n",
    "categorical_transformer = OneHotEncoder(handle_unknown = 'ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer([('cat', categorical_transformer, cat_features)])\n",
    "\n",
    "clf = Pipeline([('preprocessor', preprocessor), \n",
    "               ('classifier', RandomForestClassifier(verbose = 1, random_state = 42))])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train, y_hat, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    " 'classifier__max_depth': [3,10, None],\n",
    " 'classifier__criterion': ['gini', 'entropy'],\n",
    " 'classifier__min_samples_leaf': [1, 2, 4],\n",
    " 'classifier__n_estimators': [100, 500],\n",
    " 'classifier__class_weight': ['balanced', 'balanced_subsample'],\n",
    " 'classifier__n_jobs': [-1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, n_jobs=-1, cv = 3, return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(clf.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names(input_features = cat_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_import_desc = list(clf.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names(input_features = cat_features))\n",
    "feat_import_num = grid_search.best_estimator_.named_steps['classifier'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imprt = pd.DataFrame(list(zip(feat_import_desc, feat_import_num)), columns=('category', 'value'))\n",
    "for value in cat_features:\n",
    "    if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = grid_search.predict(X_train)\n",
    "\n",
    "print('recall score:', recall_score(y_train, yhat, average = 'macro'))\n",
    "print('precision score:', precision_score(y_train, yhat, average = 'macro'))\n",
    "print('f1 score:', f1_score(y_train, yhat, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_search, X_train, y_train)\n",
    "plt.grid(None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ROCAUC(clf)\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_train, y_train)\n",
    "visualizer.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = grid_search.predict(X_test)\n",
    "\n",
    "print('recall score:', recall_score(y_test, y_hat_test, average = 'macro'))\n",
    "print('precision score:', precision_score(y_test, y_hat_test, average = 'macro'))\n",
    "print('f1 score:', f1_score(y_test, y_hat_test, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(grid_search, X_test, y_test)\n",
    "plt.grid(None)\n",
    "plt.savefig('saved_objects/final_confusion');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ROCAUC(clf)\n",
    "visualizer.fit(X_test, y_test)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.show()\n",
    "plt.savefig('saved_objects/final_ROC_AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "X_poly_train = pd.DataFrame(poly.fit_transform(X_train), columns=poly.get_feature_names(features.columns))\n",
    "X_poly_test = pd.DataFrame(poly.transform(X_test), columns=poly.get_feature_names(features.columns))\n",
    "X_poly_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "threshold_ranges = np.linspace(0, 2, num=6)\n",
    "\n",
    "for thresh in threshold_ranges:\n",
    "    print(thresh)\n",
    "    selector = VarianceThreshold(thresh)\n",
    "    reduced_feature_train = selector.fit_transform(X_train)\n",
    "    reduced_feature_test = selector.transform(X_test)\n",
    "    lr = RandomForestClassifier()\n",
    "    lr.fit(reduced_feature_train, y_train)\n",
    "    run_model(lr, reduced_feature_train, reduced_feature_test, y_train, y_test)\n",
    "    print('--------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
