{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80a34b3-e120-4dab-b78b-e508821320ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import  compute_sample_weight\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dbed2a-208c-47a4-8dad-cca0315a248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr=df_.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "df_corr['pairs'] = list(zip(df_corr.level_0, df_corr.level_1))\n",
    "df_corr.set_index(['pairs'], inplace = True)\n",
    "df_corr.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "df_corr.columns = ['cc']\n",
    "df_corr.drop_duplicates(inplace=True)\n",
    "df_corr = df_corr[df_corr['cc'] < 1.0000]\n",
    "df_corr.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042bcb4-2b2b-473e-88b8-a98c2f0ff97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_feats = set()\n",
    "corr = df_.corr()\n",
    "\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr.iloc[i, j]) > 0.85:\n",
    "            colname = corr.columns[i]\n",
    "            corr_feats.add(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189662c-54b1-4a56-9c8d-4e6722408847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_.drop(corr_feats, axis=1)\n",
    "test_df = test_df.drop(corr_feats, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287256aa-d168-4a77-8d2c-60075ce1d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_cols = ['date_recorded', 'recorded_by', 'wpt_name', 'Unnamed: 0.1', 'id']\n",
    "df_.drop(unwanted_cols, axis=1, inplace=True)\n",
    "test_df.drop(unwanted_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d6660-a6d9-4458-9d7d-f4333410bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4061667-83bf-4af7-a486-ab99f0907448",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df_.columns.tolist() if col != 'status_group']\n",
    "\n",
    "test_df = test_df.reindex(columns=[col for col in df_.columns]).drop('status_group', axis=1)\n",
    "\n",
    "test_df.columns.tolist() == cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcef15b-93e0-46fa-be94-fb63343a4175",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sample_weights = compute_sample_weight('balanced', y)\n",
    "\n",
    "X = df_.drop(['status_group'], axis=1).select_dtypes(['int', 'float'])\n",
    "y = df_['status_group']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X,y, random_state=42, stratify=y)\n",
    "X_val, X_test_, y_val, y_test_ = train_test_split(X_test_, y_test_, random_state=42, stratify=y_test_)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_hat_train = rf.predict(X_train)\n",
    "y_hat = rf.predict(X_test)\n",
    "\n",
    "print('Train Accuracy Score:', accuracy_score(y_hat_train, y_train))\n",
    "print('Test Accuracy Score:', accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ba726a-0a24-4f7a-8c63-100bceba3bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import  compute_sample_weight\n",
    "from sklearn.model_selection import cross_val_score\n",
    "sample_weights = compute_sample_weight('balanced', y)\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, \\\n",
    "                    n_jobs=-1,\n",
    "                    tree_method='gpu_hist',\n",
    "                    objective='multi:softprob',\n",
    "                    sample_weight=sample_weights)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_hat = xgb.predict(X_test)\n",
    "print('Train Accuracy score:', accuracy_score(y_hat_train, y_train))\n",
    "# print('Accuracy score:', accuracy_score(y_test, y_hat))\n",
    "print('Test Accuracy Score:', accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745ee38-675c-4ac6-bf7b-f37b2f6a89aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    print(\"Training with params: \")\n",
    "    print(params)\n",
    "    watchlist = [(X_train_, y_train_), (X_val, y_val)]\n",
    "    gbm_model = XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        n_estimators = int(params['n_estimators']),\n",
    "        max_depth= params['max_depth'],\n",
    "        min_child_weight= params['min_child_weight'],\n",
    "        subsample= params['subsample'],\n",
    "        gamma= params['gamma'],\n",
    "        colsample_bytree= params['colsample_bytree'],\n",
    "        eta= params['eta'],\n",
    "        eval_metric= 'mlogloss',\n",
    "        objective= 'multi:softmax',\n",
    "        tree_method='gpu_hist',\n",
    "        booster= 'gbtree',\n",
    "        silent= 1,\n",
    "        seed= 42,\n",
    "        num_class= 3,\n",
    "        sample_weight=sample_weights\n",
    "    )\n",
    "    gbm_model.fit(X_train_, y_train_,\n",
    "                  eval_set=watchlist)\n",
    "    predictions = gbm_model.predict(X_test_)\n",
    "\n",
    "    score_ = cross_val_score(gbm_model, X_train_, y_train_, cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score_))\n",
    "\n",
    "    return {'loss': -score_, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "def optimize(trials):\n",
    "    \"\"\"\n",
    "    This is the optimization function that given a space (space here) of\n",
    "    hyperparameters and a scoring function (score here), finds the best hyperparameters.\n",
    "    \"\"\"\n",
    "\n",
    "    space = {\n",
    "        'n_estimators': hp.quniform('n_estimators', 10, 1000, 1),\n",
    "        'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "        'max_depth':  hp.choice('max_depth', np.arange(1, 20, dtype=int)),\n",
    "        'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "        'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "        'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "        'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "    }\n",
    "    # Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "    best = fmin(score, \\\n",
    "                space, \\\n",
    "                algo=tpe.suggest, \\\n",
    "                trials=trials, \\\n",
    "                max_evals=1000)\n",
    "    return best\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = optimize(trials)\n",
    "print(\"The best hyperparameters are: \", \"\\n\")\n",
    "print(best_hyperparams)\n",
    "\n",
    "print(\"Best Parameters: {'colsample_bytree': 0.6000000000000001, 'eta': 0.025, 'gamma': 0.55, 'max_depth': 7, 'min_child_weight': 2.0, 'n_estimators': 680.0, 'subsample': 1.0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb0df5-71ac-4b08-b875-f07d76d465b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(use_label_encoder=False,\n",
    "                    eval_metric= 'mlogloss',\n",
    "                    objective= 'multi:softmax',\n",
    "                    tree_method='gpu_hist',\n",
    "                    booster= 'gbtree',\n",
    "                    silent= 1,\n",
    "                    seed= 42,\n",
    "                    num_class= 3,\n",
    "                    sample_weight=sample_weights,\n",
    "                    colsample_bytree=0.7,\n",
    "                    eta=0.075,\n",
    "                    gamma=0.65,\n",
    "                    max_depth=6,\n",
    "                    mind_child_weight=6,\n",
    "                    n_estimators=166,\n",
    "                    subsample=0.75\n",
    "                    )\n",
    "\n",
    "watchlist = [(X_train_, y_train_), (X_val, y_val)]\n",
    "\n",
    "xgb.fit(X_train_, y_train_, eval_set=watchlist)\n",
    "y_hat_train = xgb.predict(X_train_)\n",
    "y_hat = xgb.predict(X_test_)\n",
    "#\n",
    "# y_hat = clf.predict(X_test)\n",
    "print('Train Accuracy score:', accuracy_score(y_hat_train, y_train_))\n",
    "# # print('Accuracy score:', accuracy_score(y_test, y_hat))\n",
    "print('Test Accuracy Score:', accuracy_score(y_test_, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4225966-4d3c-456a-92e6-81a7aae06521",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_ = test_df[[col for col in X.columns]]\n",
    "pred = pd.DataFrame(le.inverse_transform(xgb.predict(test_df_)), columns=['status_group'])\n",
    "sub_idx = pd.DataFrame(pd.read_csv(test_url)['id'])\n",
    "sub_idx.reset_index(drop=True, inplace=True)\n",
    "final_sub = pd.concat([sub_idx, pred], axis=1)\n",
    "final_sub.reset_index(drop=True, inplace=True)\n",
    "final_sub.set_index('id').to_csv('data/final_sub.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgboost",
   "language": "python",
   "name": "xgboost"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
